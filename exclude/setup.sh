#!/bin/bash
# setup.sh - RunPod GPU í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ (CUDA ì§€ì›)

echo "======================================"
echo "RunPod GPU í™˜ê²½ ì„¤ì • ì‹œì‘"
echo "======================================"

# ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
echo "[1/7] ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì—…ë°ì´íŠ¸..."
apt-get update -qq

# Python í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo "[2/7] Python ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜..."
pip install --upgrade pip -q
pip install tqdm psutil -q

# ê¸°ì¡´ llama-cpp-python ì œê±°
echo "[3/7] ê¸°ì¡´ llama-cpp-python ì œê±°..."
pip uninstall llama-cpp-python -y -q 2>/dev/null || true

# CUDA ì§€ì› llama-cpp-python ì„¤ì¹˜
echo "[4/7] CUDA ì§€ì› llama-cpp-python ì„¤ì¹˜..."
echo "  (ì´ ë‹¨ê³„ëŠ” 2-5ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)"
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121

# ì„¤ì¹˜ í™•ì¸
echo "[5/7] llama-cpp-python ì„¤ì¹˜ í™•ì¸..."
python3 -c "from llama_cpp import Llama; print('âœ… llama-cpp-python ì„¤ì¹˜ ì„±ê³µ')" || {
    echo "âŒ llama-cpp-python ì„¤ì¹˜ ì‹¤íŒ¨!"
    echo "ì¬ì‹œë„ ì¤‘ (ì†ŒìŠ¤ ë¹Œë“œ)..."
    CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python --force-reinstall --no-cache-dir
}

# ë””ë ‰í† ë¦¬ ìƒì„±
echo "[6/7] ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±..."
mkdir -p models
mkdir -p output
mkdir -p checkpoint

# GPU í™•ì¸
echo "[7/7] GPU í™˜ê²½ í™•ì¸..."
echo ""
echo "=== NVIDIA GPU ì •ë³´ ==="
nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv,noheader 2>/dev/null || echo "âš ï¸  nvidia-smi ì‹¤í–‰ ì‹¤íŒ¨"

echo ""
echo "=== CUDA ë²„ì „ ==="
nvcc --version 2>/dev/null | grep "release" || echo "CUDA: $(cat /usr/local/cuda/version.txt 2>/dev/null || echo 'N/A')"

echo ""
echo "=== PyTorch CUDA í™•ì¸ (ì„ íƒì‚¬í•­) ==="
python3 -c "import torch; print(f'PyTorch CUDA available: {torch.cuda.is_available()}'); print(f'PyTorch CUDA version: {torch.version.cuda if torch.cuda.is_available() else \"N/A\"}'); print(f'GPU count: {torch.cuda.device_count()}')" 2>/dev/null || echo "PyTorch not installed (optional)"

echo ""
echo "======================================"
echo "âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ!"
echo "======================================"
echo ""
echo "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:"
echo "1. models/ ë””ë ‰í† ë¦¬ì— base_model.ggufì™€ lora.gguf ì—…ë¡œë“œ"
echo "2. dataset.jsonl íŒŒì¼ ì—…ë¡œë“œ"
echo "3. python run_inference.py ì‹¤í–‰"
echo ""
echo "ğŸ” GPU ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§:"
echo "   watch -n 1 nvidia-smi"
echo ""